{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"text_emotion.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"tweet_id\",\"author\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing text\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "punct = string.punctuation + \"’\"\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in punct])\n",
    "    return no_punct.lower()\n",
    "\n",
    "data[\"content\"] = data[\"content\"].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "data[\"content\"] = data[\"content\"].apply(lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "data[\"content\"] = data[\"content\"].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "data[\"content\"] = data[\"content\"].apply(lambda x:\" \".join(x))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(data['content'])\n",
    "\n",
    "X = vectorizer.transform(data['content'])\n",
    "Y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the data in validation and train set for evaluation\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        31\n",
      "     boredom       0.00      0.00      0.00        38\n",
      "       empty       0.00      0.00      0.00       198\n",
      "  enthusiasm       0.00      0.00      0.00       175\n",
      "         fun       0.29      0.01      0.02       452\n",
      "   happiness       0.35      0.36      0.35      1314\n",
      "        hate       0.53      0.12      0.20       339\n",
      "        love       0.53      0.34      0.41       968\n",
      "     neutral       0.33      0.61      0.43      2234\n",
      "      relief       0.32      0.02      0.03       381\n",
      "     sadness       0.37      0.23      0.29      1265\n",
      "    surprise       0.26      0.02      0.03       558\n",
      "       worry       0.33      0.49      0.40      2047\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.26      0.17      0.17     10000\n",
      "weighted avg       0.35      0.35      0.31     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs',multi_class='auto')\n",
    "lr_model.fit(train_x,train_y)\n",
    "\n",
    "lr_pred = lr_model.predict(test_x)\n",
    "print(classification_report(test_y, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        31\n",
      "     boredom       0.00      0.00      0.00        38\n",
      "       empty       0.00      0.00      0.00       198\n",
      "  enthusiasm       0.00      0.00      0.00       175\n",
      "         fun       0.00      0.00      0.00       452\n",
      "   happiness       0.37      0.10      0.15      1314\n",
      "        hate       0.00      0.00      0.00       339\n",
      "        love       0.65      0.13      0.22       968\n",
      "     neutral       0.32      0.44      0.37      2234\n",
      "      relief       0.00      0.00      0.00       381\n",
      "     sadness       0.26      0.01      0.01      1265\n",
      "    surprise       0.00      0.00      0.00       558\n",
      "       worry       0.26      0.80      0.39      2047\n",
      "\n",
      "    accuracy                           0.29     10000\n",
      "   macro avg       0.14      0.11      0.09     10000\n",
      "weighted avg       0.27      0.29      0.21     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Naïve Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(train_x,train_y)\n",
    "\n",
    "mnb_pred = mnb_model.predict(test_x)\n",
    "print(classification_report(test_y, mnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        31\n",
      "     boredom       0.00      0.00      0.00        38\n",
      "       empty       0.03      0.01      0.01       198\n",
      "  enthusiasm       0.03      0.01      0.01       175\n",
      "         fun       0.10      0.04      0.05       452\n",
      "   happiness       0.29      0.28      0.29      1314\n",
      "        hate       0.33      0.19      0.24       339\n",
      "        love       0.39      0.45      0.42       968\n",
      "     neutral       0.35      0.48      0.41      2234\n",
      "      relief       0.14      0.05      0.08       381\n",
      "     sadness       0.28      0.26      0.27      1265\n",
      "    surprise       0.12      0.03      0.05       558\n",
      "       worry       0.33      0.43      0.37      2047\n",
      "\n",
      "    accuracy                           0.32     10000\n",
      "   macro avg       0.18      0.17      0.17     10000\n",
      "weighted avg       0.29      0.32      0.30     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(train_x,train_y)\n",
    "\n",
    "sgd_pred = sgd_model.predict(test_x)\n",
    "print(classification_report(test_y, sgd_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        31\n",
      "     boredom       0.00      0.00      0.00        38\n",
      "       empty       0.01      0.04      0.02       198\n",
      "  enthusiasm       0.00      0.00      0.00       175\n",
      "         fun       0.00      0.00      0.00       452\n",
      "   happiness       0.26      0.03      0.05      1314\n",
      "        hate       0.22      0.01      0.02       339\n",
      "        love       0.57      0.08      0.13       968\n",
      "     neutral       0.23      0.80      0.36      2234\n",
      "      relief       0.25      0.00      0.01       381\n",
      "     sadness       0.23      0.01      0.03      1265\n",
      "    surprise       0.00      0.00      0.00       558\n",
      "       worry       0.22      0.11      0.15      2047\n",
      "\n",
      "    accuracy                           0.22     10000\n",
      "   macro avg       0.15      0.08      0.06     10000\n",
      "weighted avg       0.23      0.22      0.13     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbours\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(train_x,train_y)\n",
    "\n",
    "knn_pred = knn_model.predict(test_x)\n",
    "print(classification_report(test_y, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        31\n",
      "     boredom       0.00      0.00      0.00        38\n",
      "       empty       0.01      0.01      0.01       198\n",
      "  enthusiasm       0.04      0.02      0.03       175\n",
      "         fun       0.08      0.06      0.07       452\n",
      "   happiness       0.25      0.30      0.27      1314\n",
      "        hate       0.22      0.16      0.19       339\n",
      "        love       0.35      0.31      0.33       968\n",
      "     neutral       0.35      0.41      0.38      2234\n",
      "      relief       0.07      0.04      0.05       381\n",
      "     sadness       0.23      0.22      0.23      1265\n",
      "    surprise       0.08      0.06      0.07       558\n",
      "       worry       0.28      0.32      0.30      2047\n",
      "\n",
      "    accuracy                           0.27     10000\n",
      "   macro avg       0.15      0.15      0.15     10000\n",
      "weighted avg       0.25      0.27      0.26     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(train_x,train_y)\n",
    "\n",
    "dt_pred = dt_model.predict(test_x)\n",
    "print(classification_report(test_y, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        31\n",
      "     boredom       0.08      0.03      0.04        38\n",
      "       empty       0.07      0.02      0.02       198\n",
      "  enthusiasm       0.00      0.00      0.00       175\n",
      "         fun       0.13      0.05      0.07       452\n",
      "   happiness       0.27      0.31      0.29      1314\n",
      "        hate       0.28      0.14      0.19       339\n",
      "        love       0.40      0.32      0.36       968\n",
      "     neutral       0.33      0.56      0.41      2234\n",
      "      relief       0.13      0.03      0.05       381\n",
      "     sadness       0.25      0.19      0.22      1265\n",
      "    surprise       0.13      0.03      0.05       558\n",
      "       worry       0.30      0.34      0.32      2047\n",
      "\n",
      "    accuracy                           0.30     10000\n",
      "   macro avg       0.18      0.15      0.16     10000\n",
      "weighted avg       0.27      0.30      0.27     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(train_x,train_y)\n",
    "\n",
    "rf_pred = rf_model.predict(test_x)\n",
    "print(classification_report(test_y, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        31\n",
      "     boredom       0.00      0.00      0.00        38\n",
      "       empty       0.00      0.00      0.00       198\n",
      "  enthusiasm       0.00      0.00      0.00       175\n",
      "         fun       0.10      0.00      0.01       452\n",
      "   happiness       0.33      0.38      0.35      1314\n",
      "        hate       0.44      0.15      0.22       339\n",
      "        love       0.51      0.36      0.42       968\n",
      "     neutral       0.35      0.60      0.44      2234\n",
      "      relief       0.38      0.03      0.05       381\n",
      "     sadness       0.37      0.22      0.27      1265\n",
      "    surprise       0.28      0.03      0.05       558\n",
      "       worry       0.34      0.48      0.40      2047\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.24      0.17      0.17     10000\n",
      "weighted avg       0.33      0.35      0.31     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(train_x,train_y)\n",
    "\n",
    "svm_pred = svm_model.predict(test_x)\n",
    "print(classification_report(test_y, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
